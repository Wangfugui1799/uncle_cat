**问题分析**：
章节字数填了1000，但实际生成2000字左右的主要原因：

1. **提示词要求不够严格**：虽然在提示词中要求了字数，但AI模型可能不会严格遵守
2. **tokens和中文的转换问题**：1个中文汉字约等于2个tokens，当前固定的max\_tokens设置可能导致生成过多内容
3. **max\_tokens设置固定**：没有根据用户输入的word\_count动态调整API请求的max\_tokens参数
4. **缺乏后处理字数限制**：没有在生成后对内容进行字数裁剪

**优化方案**：

1. **优化提示词中的字数控制**：

   * 加强提示词中的字数要求，明确指定误差范围

   * 添加具体的字数控制说明

2. **动态调整max\_tokens**：

   * 根据用户输入的word\_count计算合适的max\_tokens值

   * 考虑中文和tokens的转换关系（1汉字≈2tokens）

   * 为不同模型设置合理的max\_tokens

3. **添加后处理字数裁剪**：

   * 在生成内容后，根据用户要求的字数进行裁剪

   * 确保裁剪后的内容保持完整性

4. **优化API请求参数**：

   * 在API请求中添加更严格的字数控制参数

   * 针对不同模型设置合适的参数

**修改点**：

1. **文件**：`services/apiService.ts`

   * 函数：`generateContent`

   * 内容：根据word\_count动态调整max\_tokens

2. **文件**：`constants.ts`

   * 内容：优化章节提示词中的字数控制要求

3. **文件**：`App.tsx`

   * 函数：`handleGenerateChapter`

   * 内容：添加后处理字数裁剪

**预期效果**：

* 用户设置1000字时，实际生成字数在900-1100字之间

* 不同模型生成的字数都能符合用户要求

* 提高字数控制的准确性

* 保持生成内容

